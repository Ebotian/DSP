{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fecc6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "type(tf.keras.callbacks.TensorBoard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f08ac",
   "metadata": {},
   "source": [
    "This code imports the `datetime` and `tensorflow` modules, and then checks the type of the `TensorBoard` class from the `tensorflow.keras.callbacks` module.\n",
    "\n",
    "The `datetime` module provides classes for working with dates and times in Python. The `tensorflow` module is a popular open-source machine learning library developed by Google. The `TensorBoard` class is a callback function in TensorFlow that can be used to visualize the training process of a machine learning model.\n",
    "\n",
    "The commented out line of code (`# from tensorflow.keras.callbacks import TensorBoard`) suggests that the `TensorBoard` callback may be used later in the notebook to monitor the training of a model.\n",
    "\n",
    "The `type()` function is used to check the type of an object in Python. In this case, it is used to check the type of the `TensorBoard` class. The output of the code is the type of the `TensorBoard` class, which is `<class 'type'>`.\n",
    "\n",
    "I hope this helps! Let me know if you have any further questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cb07fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# cuDNN can sometimes fail to initialize when TF reserves all of the GPU memory\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Load and prepare the MNIST dataset.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6a98f",
   "metadata": {},
   "source": [
    "This code snippet contains two parts. The first part is a comment that explains that cuDNN (a library for deep neural networks) can sometimes fail to initialize when TensorFlow reserves all of the GPU memory.\n",
    "\n",
    "The second part of the code loads and prepares the MNIST dataset using the `tf.keras.datasets.mnist.load_data()` function. The MNIST dataset is a collection of handwritten digits that is commonly used for training and testing machine learning models.\n",
    "\n",
    "The dataset is split into two sets: a training set (`x_train` and `y_train`) and a test set (`x_test` and `y_test`). The `x_train` and `x_test` arrays contain the images of the digits, while the `y_train` and `y_test` arrays contain the corresponding labels.\n",
    "\n",
    "The `physical_devices` variable is used to get a list of all the available physical devices (in this case, GPUs) on the system. The `tf.config.experimental.set_memory_growth()` function is then used to set the memory growth option for the first GPU in the list to `True`. This allows TensorFlow to allocate memory on the GPU as needed, rather than reserving all of the memory at once.\n",
    "\n",
    "The `try` and `except` statements are used to handle any errors that may occur when setting the memory growth option. If an error occurs, the `pass` statement is used to do nothing and continue with the rest of the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78f3b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(x_train.shape)\n",
    "# (60000,28,28)\n",
    "\n",
    "# Preprocess the data (these are Numpy arrays)\n",
    "x_train = x_train.reshape(60000, 28, 28, 1).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "# print(x_train.shape)\n",
    "# (60000,28,28,1)\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14ea0fe",
   "metadata": {},
   "source": [
    "This code excerpt preprocesses the MNIST dataset by reshaping the input data and normalizing the pixel values. It also reserves 10,000 samples for validation.\n",
    "\n",
    "The first two lines of code are commented out, but they show the original shape of the `x_train` array before preprocessing. The `x_train` and `x_test` arrays are then reshaped using the `reshape()` method to have a shape of `(number of samples, height, width, channels)`. In this case, the height and width are both 28, and there is only one channel (since the images are grayscale).\n",
    "\n",
    "The `astype()` method is used to convert the `y_train` and `y_test` arrays to `float32` data type. This is necessary for compatibility with the TensorFlow library.\n",
    "\n",
    "The last four lines of code reserve 10,000 samples from the training set for validation. The `x_val` and `y_val` arrays are created by slicing the last 10,000 samples from the `x_train` and `y_train` arrays, respectively. The remaining samples are used for training by slicing the `x_train` and `y_train` arrays up to the last 10,000 samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0182f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-08 09:52:12.251821: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Define our model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.AveragePooling2D(),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(120, activation='relu'),\n",
    "    tf.keras.layers.Dense(84, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4136a",
   "metadata": {},
   "source": [
    "This code defines a convolutional neural network (CNN) model architecture using the Keras API in TensorFlow.\n",
    "\n",
    "The `tf.keras.Sequential()` function is used to create a sequential model, which is a linear stack of layers. The layers are defined as a list of objects that are added to the model in the order they are specified.\n",
    "\n",
    "The model architecture consists of the following layers:\n",
    "\n",
    "- `Conv2D` layer with 6 filters, a kernel size of (3, 3), and a ReLU activation function. This layer applies 6 convolutional filters to the input image, each with a kernel size of 3x3 pixels. The ReLU activation function is used to introduce non-linearity into the model.\n",
    "\n",
    "- `AveragePooling2D` layer. This layer applies average pooling to the output of the previous layer, which reduces the spatial dimensions of the feature maps.\n",
    "\n",
    "- `Conv2D` layer with 16 filters, a kernel size of (3, 3), and a ReLU activation function. This layer applies 16 convolutional filters to the output of the previous layer, each with a kernel size of 3x3 pixels.\n",
    "\n",
    "- `Flatten` layer. This layer flattens the output of the previous layer into a 1D array, which can be fed into a fully connected layer.\n",
    "\n",
    "- `Dense` layer with 120 units and a ReLU activation function. This layer is a fully connected layer that applies 120 hidden units to the input.\n",
    "\n",
    "- `Dense` layer with 84 units and a ReLU activation function. This layer is another fully connected layer that applies 84 hidden units to the input.\n",
    "\n",
    "- `Dense` layer with 10 units and a softmax activation function. This layer is the output layer of the model, which applies 10 output units to the input (one for each class in the MNIST dataset) and uses the softmax activation function to convert the output to a probability distribution over the classes.\n",
    "\n",
    "Overall, this model architecture is known as LeNet-5 and is commonly used for image classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee0a0118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "1563/1563 [==============================] - 269s 170ms/step - loss: 0.1835 - accuracy: 0.9461 - val_loss: 0.0725 - val_accuracy: 0.9769\n",
      "Epoch 2/6\n",
      "1563/1563 [==============================] - 228s 146ms/step - loss: 0.0622 - accuracy: 0.9805 - val_loss: 0.0560 - val_accuracy: 0.9821\n",
      "Epoch 3/6\n",
      "1563/1563 [==============================] - 226s 145ms/step - loss: 0.0403 - accuracy: 0.9871 - val_loss: 0.0444 - val_accuracy: 0.9862\n",
      "Epoch 4/6\n",
      "1563/1563 [==============================] - 224s 143ms/step - loss: 0.0296 - accuracy: 0.9902 - val_loss: 0.0500 - val_accuracy: 0.9839\n",
      "Epoch 5/6\n",
      "1563/1563 [==============================] - 211s 135ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0621 - val_accuracy: 0.9805\n",
      "Epoch 6/6\n",
      "1563/1563 [==============================] - 216s 138ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.0534 - val_accuracy: 0.9847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6d3f01fd50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Connect to Tensorboard and train the model\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"tflogs/{}\".format(datetime.datetime.now().replace(microsecond=0).isoformat()))\n",
    "\n",
    "model.fit(x_train, y_train, validation_data=(\n",
    "    x_test, y_test), epochs=6, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68387bb6",
   "metadata": {},
   "source": [
    "This code compiles and trains the LeNet-5 model using the Keras API in TensorFlow.\n",
    "\n",
    "The `model.compile()` function is used to configure the model for training. The `optimizer` argument specifies the optimization algorithm to use during training. In this case, the Adam optimizer is used, which is a popular optimization algorithm for deep learning models. The `loss` argument specifies the loss function to use during training. In this case, the sparse categorical cross-entropy loss function is used, which is commonly used for multi-class classification problems. The `metrics` argument specifies the evaluation metric to use during training. In this case, the accuracy metric is used to evaluate the performance of the model.\n",
    "\n",
    "The `tf.keras.callbacks.TensorBoard()` function is used to connect to TensorBoard, which is a visualization tool for TensorFlow. The `log_dir` argument specifies the directory where the log files for TensorBoard will be stored. The `datetime.datetime.now().replace(microsecond=0).isoformat()` function is used to generate a unique timestamp for the log directory.\n",
    "\n",
    "The `model.fit()` function is used to train the model on the MNIST dataset. The `x_train` and `y_train` arrays are used as the training data, and the `x_test` and `y_test` arrays are used as the validation data. The `epochs` argument specifies the number of epochs to train the model for. In this case, the model is trained for 6 epochs. The `callbacks` argument specifies a list of callbacks to use during training. In this case, the `tensorboard` callback is used to log the training progress to TensorBoard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57382471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Testing trained model...\n",
      "Test loss: 0.03398682527573219\n",
      "Test accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "print('================================================================================')\n",
    "print('Testing trained model...')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "model.save_weights('models/lenet5_weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243b93e7",
   "metadata": {},
   "source": [
    "This code excerpt evaluates the performance of the trained LeNet-5 model on the test set and saves the model weights to a file.\n",
    "\n",
    "The first two lines of code print out a header message to indicate that the testing of the model is starting.\n",
    "\n",
    "The `model.evaluate()` function is used to evaluate the performance of the model on the test set. The `x_test` and `y_test` arrays are used as the test data. The `verbose` argument is set to 0 to suppress the output of the evaluation during testing. The `score` variable is used to store the test loss and accuracy of the model.\n",
    "\n",
    "The next two lines of code print out the test loss and accuracy of the model.\n",
    "\n",
    "The `model.save_weights()` function is used to save the weights of the trained model to a file. The `lenet5_weights` file is saved in the `models` directory. The weights can be loaded later to make predictions on new data without having to retrain the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "53820a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08893549, 0.06382666, 0.08425631, 0.07245415, 0.08965157,\n",
       "        0.07504291, 0.08201154, 0.05295953, 0.30825508, 0.08260679]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import imshow\n",
    "x = x_test[3]\n",
    "imshow(x)\n",
    "x = x.reshape(1, 28, 28, 1).astype('float32') / 255\n",
    "x = x.astype('float32')\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72528bc7",
   "metadata": {},
   "source": [
    "This code excerpt from the `lenet-5.ipynb` notebook file displays an image from the test set and makes a prediction using the trained LeNet-5 model.\n",
    "\n",
    "The `from pylab import imshow` statement imports the `imshow()` function from the `pylab` module, which is a part of the Matplotlib library for data visualization.\n",
    "\n",
    "The `x_test[3]` statement selects the fourth image from the test set (Python uses 0-based indexing).\n",
    "\n",
    "The `imshow(x)` statement displays the selected image using the `imshow()` function.\n",
    "\n",
    "The `x.reshape(1, 28, 28, 1).astype('float32') / 255` statement reshapes the image to have a shape of `(1, 28, 28, 1)` and normalizes the pixel values to be between 0 and 1.\n",
    "\n",
    "The `x.astype('float32')` statement converts the image to the `float32` data type, which is compatible with the TensorFlow library.\n",
    "\n",
    "The `model.predict(x)` statement makes a prediction using the trained LeNet-5 model on the selected image. The output of the `predict()` method is a probability distribution over the classes in the MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc4846ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7762419e-05, 1.7852648e-05, 7.3196162e-08, 1.5698429e-10,\n",
       "        9.1076350e-01, 4.9194443e-07, 6.8887986e-02, 2.0302102e-02,\n",
       "        1.0204633e-05, 1.4164810e-09]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.image import load_img,img_to_array\n",
    "img = load_img(\"./test/3.png\",target_size=(28,28))\n",
    "img=img.convert(\"L\")\n",
    "img.save(\"./test/3_1.png\")\n",
    "x=img_to_array(img)\n",
    "x=x.reshape(1, 28, 28, 1).astype('float32') / 255\n",
    "x=x.astype('float32')\n",
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a73fbeb",
   "metadata": {},
   "source": [
    "This code excerpt loads an image file, preprocesses it, and makes a prediction using the trained LeNet-5 model.\n",
    "\n",
    "The `from tensorflow.python.keras.preprocessing.image import load_img,img_to_array` statement imports the `load_img()` and `img_to_array()` functions from the `tensorflow.python.keras.preprocessing.image` module. These functions are used to load and preprocess the image.\n",
    "\n",
    "The `load_img(\"./test/3.png\",target_size=(28,28))` statement loads the image file located at `./test/3.png` and resizes it to have a shape of `(28, 28)`.\n",
    "\n",
    "The `img=img.convert(\"L\")` statement converts the image to grayscale.\n",
    "\n",
    "The `img.save(\"./test/3_1.png\")` statement saves the preprocessed image to a file named `3_1.png` in the `./test` directory.\n",
    "\n",
    "The `img_to_array(img)` statement converts the preprocessed image to a Numpy array.\n",
    "\n",
    "The `x.reshape(1, 28, 28, 1).astype('float32') / 255` statement reshapes the image to have a shape of `(1, 28, 28, 1)` and normalizes the pixel values to be between 0 and 1.\n",
    "\n",
    "The `x.astype('float32')` statement converts the image to the `float32` data type, which is compatible with the TensorFlow library.\n",
    "\n",
    "The `model.predict(x)` statement makes a prediction using the trained LeNet-5 model on the preprocessed image. The output of the `predict()` method is a probability distribution over the classes in the MNIST dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
